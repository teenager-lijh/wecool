{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:36.864446Z",
     "start_time": "2024-04-25T02:08:36.813437Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 3, 224, 224])\n",
      "outputs.shape : torch.Size([8, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "inputs = torch.rand(size=(8, 3, 224, 224))\n",
    "conv = DoubleConv(in_channels=3, out_channels=32)\n",
    "outputs = conv(inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:36.965837Z",
     "start_time": "2024-04-25T02:08:36.819188Z"
    }
   },
   "id": "d186ca84d780befe"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 16, 224, 224])\n",
      "outputs.shape : torch.Size([8, 32, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "inputs = torch.rand(size=(8, 16, 224, 224))\n",
    "down = Down(in_channels=16, out_channels=32)\n",
    "outputs = down(inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:36.967015Z",
     "start_time": "2024-04-25T02:08:36.901285Z"
    }
   },
   "id": "5c4bd9ca0b8e6de9"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 16, 224, 224])\n",
      "outputs.shape : torch.Size([8, 8, 448, 448])\n"
     ]
    }
   ],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # 逆卷积, kernel_size 和 stride 是相对于正卷积的过程而说的\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.up(x)  # 这一步就将 x1 的通道数减半了\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "inputs = torch.rand(size=(8, 16, 224, 224))\n",
    "up = Up(in_channels=16*2, out_channels=16//2)\n",
    "outputs = up(inputs, inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:37.824126Z",
     "start_time": "2024-04-25T02:08:36.965991Z"
    }
   },
   "id": "aba8ec68dfa2fce1"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 16, 224, 224])\n",
      "outputs.shape : torch.Size([8, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "inputs = torch.rand(size=(8, 16, 224, 224))\n",
    "out = OutConv(in_channels=16, out_channels=32)\n",
    "outputs = out(inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:37.892071Z",
     "start_time": "2024-04-25T02:08:37.826899Z"
    }
   },
   "id": "bfddbdd0de634361"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UNet Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14463e80660c27db"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=2):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "\n",
    "        self.inc = DoubleConv(in_channels=in_channels, out_channels=32)\n",
    "        self.down1 = Down(in_channels=32, out_channels=64)\n",
    "        self.down2 = Down(in_channels=64, out_channels=128)\n",
    "        self.down3 = Down(in_channels=128, out_channels=256)\n",
    "        self.down4 = Down(in_channels=256, out_channels=512)\n",
    "        \n",
    "        self.bridge = DoubleConv(in_channels=512, out_channels=512)\n",
    "        \n",
    "        self.up4 = Up(in_channels=512 * 2, out_channels=256)\n",
    "        self.up3 = Up(in_channels=256 * 2, out_channels=128)\n",
    "        self.up2 = Up(in_channels=128 * 2, out_channels=64)\n",
    "        self.up1 = Up(in_channels=64 * 2, out_channels=32)\n",
    "        \n",
    "        self.outc = DoubleConv(in_channels=32, out_channels=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        \n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "\n",
    "        bridge = self.bridge(d4)\n",
    "\n",
    "        u4 = self.up4(bridge, d4)\n",
    "        u3 = self.up3(u4, d3)\n",
    "        u2 = self.up2(u3, d2)\n",
    "        u1 = self.up1(u2, d1)\n",
    "        \n",
    "        out = self.outc(u1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        单个样本的预测\n",
    "        :param inputs: (input_channels, height, width)\n",
    "        :return: mask_pred\n",
    "        \"\"\"\n",
    "        pred = self(inputs.unsqueeze(0)).squeeze(0)\n",
    "        _, pred = torch.max(pred.squeeze(0), dim=0)\n",
    "        pred = pred.detach()\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:37.892921Z",
     "start_time": "2024-04-25T02:08:37.866973Z"
    }
   },
   "id": "ff81b5a4deb3e148"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 3, 224, 224])\n",
      "outputs.shape : torch.Size([8, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(size=(8, 3, 224, 224))\n",
    "net = UNet(in_channels=3, out_channels=2)\n",
    "outputs = net(inputs)\n",
    "\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.210183Z",
     "start_time": "2024-04-25T02:08:37.869683Z"
    }
   },
   "id": "c44f9652baf42891"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17dff9e3295a485f"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        files = os.listdir(os.path.join(self.data_dir, 'imgs'))\n",
    "        self.files = [item.split('.')[0] for item in files]\n",
    "        self.convert = ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = self._load_img(self.files[i], is_mask=False)\n",
    "        mask = self._load_img(self.files[i], is_mask=True)\n",
    "\n",
    "        img = self.convert(img)\n",
    "        mask = self.convert(mask)\n",
    "        \n",
    "        # img = nn.functional.pad(img, (1, 1, 0, 0))\n",
    "        # mask = nn.functional.pad(mask, (1, 1, 0, 0))\n",
    "        \n",
    "        # 去掉 mask 通道的维度\n",
    "        mask = torch.squeeze(mask, dim=0)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def _load_img(self, file_name, is_mask=False):\n",
    "        data_dir = self.data_dir\n",
    "\n",
    "        if is_mask:\n",
    "            file_name = file_name + '_mask.gif'\n",
    "            data_dir = os.path.join(data_dir, 'masks')\n",
    "        else:\n",
    "            file_name = file_name + '.jpg'\n",
    "            data_dir = os.path.join(data_dir, 'imgs')\n",
    "        \n",
    "        obj = Image.open(os.path.join(data_dir, file_name))\n",
    "        obj = obj.resize(size=(480, 320))\n",
    "        \n",
    "        return obj"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.217541Z",
     "start_time": "2024-04-25T02:08:39.213055Z"
    }
   },
   "id": "cbd811f7938d03e0"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/SSD/SSD/blueberry/datasets/UNet'  # your data path\n",
    "\n",
    "# 创建数据集对象\n",
    "dataset = BasicDataset(data_dir=data_dir)\n",
    "# 创建数据加载器  ==> 关于多进程 dataloader 报错 ==> 要在 py 文件中使用 __main__\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.267483Z",
     "start_time": "2024-04-25T02:08:39.216305Z"
    }
   },
   "id": "a64daf17f07fc8b2"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape : torch.Size([1, 3, 320, 480])\n",
      "masks.shape  : torch.Size([1, 320, 480])\n"
     ]
    }
   ],
   "source": [
    "for images, masks in dataloader:\n",
    "    print(f'images.shape : {images.shape}')\n",
    "    print(f'masks.shape  : {masks.shape}')\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.303990Z",
     "start_time": "2024-04-25T02:08:39.254191Z"
    }
   },
   "id": "7a42c644b9b513df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 损失函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce39f5c897cae4c7"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.n_classes = None\n",
    "\n",
    "    def _one_hot_encoder(self, input_tensor):\n",
    "        tensor_list = []\n",
    "        for i in range(self.n_classes):\n",
    "            temp_prob = input_tensor == i  # * torch.ones_like(input_tensor)\n",
    "            tensor_list.append(temp_prob.unsqueeze(1))\n",
    "        output_tensor = torch.cat(tensor_list, dim=1)\n",
    "        return output_tensor.float()\n",
    "\n",
    "    def _dice_loss(self, score, target):\n",
    "        target = target.float()\n",
    "        smooth = 1e-5\n",
    "        intersect = torch.sum(score * target)\n",
    "        y_sum = torch.sum(target * target)\n",
    "        z_sum = torch.sum(score * score)\n",
    "        loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
    "        loss = 1 - loss\n",
    "        return loss\n",
    "\n",
    "    def forward(self, inputs, target, weight=None, softmax=False):\n",
    "        self.n_classes = inputs.size(1)\n",
    "\n",
    "        if softmax:\n",
    "            inputs = torch.softmax(inputs, dim=1)\n",
    "        target = self._one_hot_encoder(target)\n",
    "        if weight is None:\n",
    "            weight = [1] * self.n_classes\n",
    "        assert inputs.size() == target.size(), 'predict {} & target {} shape do not match'.format(inputs.size(), target.size())\n",
    "        class_wise_dice = []\n",
    "        loss = 0.0\n",
    "        for i in range(0, self.n_classes):\n",
    "            dice = self._dice_loss(inputs[:, i], target[:, i])\n",
    "            class_wise_dice.append(1.0 - dice.item())\n",
    "            loss += dice * weight[i]\n",
    "        return loss / self.n_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.314151Z",
     "start_time": "2024-04-25T02:08:39.304105Z"
    }
   },
   "id": "ef9cb8147e4a7cbb"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class CrossEntropyDiceLoss(nn.CrossEntropyLoss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    def forward(self, pred, label):\n",
    "        label = label.long()\n",
    "        loss = super().forward(pred, label)\n",
    "        loss += self.dice_loss(pred, label, softmax=True)\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.314368Z",
     "start_time": "2024-04-25T02:08:39.307099Z"
    }
   },
   "id": "ae4529c09b175888"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.7135)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pred = torch.rand(size=(8, 2, 224, 224), dtype=torch.float)\n",
    "label = torch.ones(size=(8, 224, 224), dtype=torch.long)\n",
    "loss_fn(pred, label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.324259Z",
     "start_time": "2024-04-25T02:08:39.310121Z"
    }
   },
   "id": "49b1c6408f8eeb2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义优化器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c1a3d06739cddb5"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:08:39.324456Z",
     "start_time": "2024-04-25T02:08:39.321905Z"
    }
   },
   "id": "5c5226666a4a014d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练的逻辑"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb353ecac4058d6"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, iter_num 1, loss 0.7786043882369995\n",
      "epoch 1, iter_num 2, loss 0.732941746711731\n",
      "epoch 1, iter_num 3, loss 0.6942446231842041\n",
      "epoch 1, iter_num 4, loss 0.6103910803794861\n",
      "epoch 1, iter_num 5, loss 0.5705145001411438\n",
      "epoch 1, iter_num 6, loss 0.5364541411399841\n",
      "epoch 1, iter_num 7, loss 0.5060492157936096\n",
      "epoch 1, iter_num 8, loss 0.48114022612571716\n",
      "epoch 1, iter_num 9, loss 0.4522033631801605\n",
      "epoch 1, iter_num 10, loss 0.44052189588546753\n",
      "epoch 1, iter_num 11, loss 0.4210132360458374\n",
      "epoch 1, iter_num 12, loss 0.4077134132385254\n",
      "epoch 1, iter_num 13, loss 0.3952310383319855\n",
      "epoch 1, iter_num 14, loss 0.38453152775764465\n",
      "epoch 1, iter_num 15, loss 0.37258830666542053\n",
      "epoch 1, iter_num 16, loss 0.3610352575778961\n",
      "epoch 1, iter_num 17, loss 0.34523364901542664\n",
      "epoch 1, iter_num 18, loss 0.3330628275871277\n",
      "epoch 1, iter_num 19, loss 0.31670883297920227\n",
      "epoch 1, iter_num 20, loss 0.315682053565979\n",
      "epoch 1, iter_num 21, loss 0.311465859413147\n",
      "epoch 1, iter_num 22, loss 0.2909073233604431\n",
      "epoch 1, iter_num 23, loss 0.2877430319786072\n",
      "epoch 1, iter_num 24, loss 0.26109904050827026\n",
      "epoch 1, iter_num 25, loss 0.24341852962970734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [45]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;66;03m# 把数据移动到显存中\u001B[39;00m\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;66;03m# inputs, label = inputs.to(device), labels.to(device)\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m         loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, labels\u001B[38;5;241m.\u001B[39mlong())\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;66;03m# 梯度清零\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [36]\u001B[0m, in \u001B[0;36mUNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     32\u001B[0m u3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup3(u4, d3)\n\u001B[1;32m     33\u001B[0m u2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup2(u3, d2)\n\u001B[0;32m---> 34\u001B[0m u1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mup1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutc(u1)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m/opt/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[0;32mIn [34]\u001B[0m, in \u001B[0;36mUp.forward\u001B[0;34m(self, x1, x2)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x1, x2):\n\u001B[1;32m     12\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([x1, x2], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 13\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 这一步就将 x1 的通道数减半了\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(x)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/miniconda3/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/conv.py:950\u001B[0m, in \u001B[0;36mConvTranspose2d.forward\u001B[0;34m(self, input, output_size)\u001B[0m\n\u001B[1;32m    945\u001B[0m num_spatial_dims \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    946\u001B[0m output_padding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_padding(\n\u001B[1;32m    947\u001B[0m     \u001B[38;5;28minput\u001B[39m, output_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_size,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    948\u001B[0m     num_spatial_dims, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv_transpose2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    951\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_padding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 2  # 在数据集上训练 2 轮\n",
    "iter_num = 1\n",
    "device = torch.device('cuda')  # gpu 设备\n",
    "\n",
    "net.train()  # 设置为训练模型\n",
    "# net.to(device)  # 把网络移动到 显存 上\n",
    "\n",
    "# 如果不把 网络 和 数据移动到显存中，那么在训练的时候就是使用 cpu 训练\n",
    "for epoch in range(1, epochs+1):\n",
    "    for inputs, labels in dataloader:\n",
    "        # 把数据移动到显存中\n",
    "        # inputs, label = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels.long())\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新梯度\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'epoch {epoch}, iter_num {iter_num}, loss {loss}')\n",
    "        iter_num += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T02:09:13.037901Z",
     "start_time": "2024-04-25T02:08:39.325876Z"
    }
   },
   "id": "467b5e26ea486837"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-25T02:09:13.037607Z"
    }
   },
   "id": "8fa331605c629853"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
