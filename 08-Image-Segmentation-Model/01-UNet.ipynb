{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:09.083773Z",
     "start_time": "2024-05-25T06:45:08.698711Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 3, 224, 224])\n",
      "outputs.shape : torch.Size([8, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "inputs = torch.rand(size=(8, 3, 224, 224))\n",
    "conv = DoubleConv(in_channels=3, out_channels=32)\n",
    "outputs = conv(inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:09.282210Z",
     "start_time": "2024-05-25T06:45:09.086694Z"
    }
   },
   "id": "d186ca84d780befe"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 16, 224, 224])\n",
      "outputs.shape : torch.Size([8, 32, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "inputs = torch.rand(size=(8, 16, 224, 224))\n",
    "down = Down(in_channels=16, out_channels=32)\n",
    "outputs = down(inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:09.372227Z",
     "start_time": "2024-05-25T06:45:09.275590Z"
    }
   },
   "id": "5c4bd9ca0b8e6de9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 16, 224, 224])\n",
      "outputs.shape : torch.Size([8, 8, 448, 448])\n"
     ]
    }
   ],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # 逆卷积, kernel_size 和 stride 是相对于正卷积的过程而说的\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.up(x)  # 这一步就将 x1 的通道数减半了\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "inputs = torch.rand(size=(8, 16, 224, 224))\n",
    "up = Up(in_channels=16*2, out_channels=16//2)\n",
    "outputs = up(inputs, inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:10.421961Z",
     "start_time": "2024-05-25T06:45:09.346903Z"
    }
   },
   "id": "aba8ec68dfa2fce1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 16, 224, 224])\n",
      "outputs.shape : torch.Size([8, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "inputs = torch.rand(size=(8, 16, 224, 224))\n",
    "out = OutConv(in_channels=16, out_channels=32)\n",
    "outputs = out(inputs)\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:10.502909Z",
     "start_time": "2024-05-25T06:45:10.423789Z"
    }
   },
   "id": "bfddbdd0de634361"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UNet Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14463e80660c27db"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=2):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "\n",
    "        self.inc = DoubleConv(in_channels=in_channels, out_channels=32)\n",
    "        self.down1 = Down(in_channels=32, out_channels=64)\n",
    "        self.down2 = Down(in_channels=64, out_channels=128)\n",
    "        self.down3 = Down(in_channels=128, out_channels=256)\n",
    "        self.down4 = Down(in_channels=256, out_channels=512)\n",
    "        \n",
    "        self.bridge = DoubleConv(in_channels=512, out_channels=512)\n",
    "        \n",
    "        self.up4 = Up(in_channels=512 * 2, out_channels=256)\n",
    "        self.up3 = Up(in_channels=256 * 2, out_channels=128)\n",
    "        self.up2 = Up(in_channels=128 * 2, out_channels=64)\n",
    "        self.up1 = Up(in_channels=64 * 2, out_channels=32)\n",
    "        \n",
    "        self.outc = DoubleConv(in_channels=32, out_channels=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "        \n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "\n",
    "        bridge = self.bridge(d4)\n",
    "\n",
    "        u4 = self.up4(bridge, d4)\n",
    "        u3 = self.up3(u4, d3)\n",
    "        u2 = self.up2(u3, d2)\n",
    "        u1 = self.up1(u2, d1)\n",
    "        \n",
    "        out = self.outc(u1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        单个样本的预测\n",
    "        :param inputs: (input_channels, height, width)\n",
    "        :return: mask_pred\n",
    "        \"\"\"\n",
    "        pred = self(inputs.unsqueeze(0)).squeeze(0)\n",
    "        _, pred = torch.max(pred.squeeze(0), dim=0)\n",
    "        pred = pred.detach()\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:10.503181Z",
     "start_time": "2024-05-25T06:45:10.468505Z"
    }
   },
   "id": "ff81b5a4deb3e148"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  : torch.Size([8, 3, 224, 224])\n",
      "outputs.shape : torch.Size([8, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(size=(8, 3, 224, 224))\n",
    "net = UNet(in_channels=3, out_channels=2)\n",
    "outputs = net(inputs)\n",
    "\n",
    "print(f'inputs.shape  : {inputs.shape}')\n",
    "print(f'outputs.shape : {outputs.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.116889Z",
     "start_time": "2024-05-25T06:45:10.471079Z"
    }
   },
   "id": "c44f9652baf42891"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17dff9e3295a485f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, data_dir, resize=(480, 320)):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.resize = resize\n",
    "        files = os.listdir(os.path.join(self.data_dir, 'imgs'))\n",
    "        self.files = [item.split('.')[0] for item in files]\n",
    "        self.mask_values = [0, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = self._load_img(self.files[i], is_mask=False)\n",
    "        mask = self._load_img(self.files[i], is_mask=True)\n",
    "\n",
    "        # 转化成 np.array 格式\n",
    "        img = np.asarray(img, dtype=np.float32)\n",
    "        mask = np.asarray(mask, dtype=np.int64)\n",
    "\n",
    "        # 转换成 tensor; # C, H, W; 把通道放在前面; 并且把像素值归一化到 0 到 1 之间\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1) / 255.\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def _load_img(self, file_name, is_mask=False):\n",
    "        data_dir = self.data_dir\n",
    "\n",
    "        # 构造图像的路径\n",
    "        if is_mask:\n",
    "            file_name = file_name + '_mask.gif'\n",
    "            data_dir = os.path.join(data_dir, 'masks')\n",
    "        else:\n",
    "            file_name = file_name + '.jpg'\n",
    "            data_dir = os.path.join(data_dir, 'imgs')\n",
    "\n",
    "        obj = Image.open(os.path.join(data_dir, file_name))  # 从磁盘读取一张图像\n",
    "        obj = obj.resize(size=self.resize)  # 调整图像大小\n",
    "\n",
    "        return obj"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.146663Z",
     "start_time": "2024-05-25T06:45:12.108549Z"
    }
   },
   "id": "cbd811f7938d03e0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/SSD/SSD/blueberry/datasets/UNet'  # your data path\n",
    "\n",
    "# 创建数据集对象\n",
    "dataset = BasicDataset(data_dir=data_dir)\n",
    "# 创建数据加载器  ==> 关于多进程 dataloader 报错 ==> 要在 py 文件中使用 __main__\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.162850Z",
     "start_time": "2024-05-25T06:45:12.126420Z"
    }
   },
   "id": "a64daf17f07fc8b2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape : torch.Size([1, 3, 320, 480])\n",
      "masks.shape  : torch.Size([1, 320, 480])\n"
     ]
    }
   ],
   "source": [
    "for images, masks in dataloader:\n",
    "    print(f'images.shape : {images.shape}')\n",
    "    print(f'masks.shape  : {masks.shape}')\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.222617Z",
     "start_time": "2024-05-25T06:45:12.156037Z"
    }
   },
   "id": "7a42c644b9b513df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 损失函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce39f5c897cae4c7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.n_classes = None\n",
    "\n",
    "    def _one_hot_encoder(self, input_tensor):\n",
    "        tensor_list = []\n",
    "        for i in range(self.n_classes):\n",
    "            temp_prob = input_tensor == i  # * torch.ones_like(input_tensor)\n",
    "            tensor_list.append(temp_prob.unsqueeze(1))\n",
    "        output_tensor = torch.cat(tensor_list, dim=1)\n",
    "        return output_tensor.float()\n",
    "\n",
    "    def _dice_loss(self, score, target):\n",
    "        target = target.float()\n",
    "        smooth = 1e-5\n",
    "        intersect = torch.sum(score * target)\n",
    "        y_sum = torch.sum(target * target)\n",
    "        z_sum = torch.sum(score * score)\n",
    "        loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
    "        loss = 1 - loss\n",
    "        return loss\n",
    "\n",
    "    def forward(self, inputs, target, weight=None, softmax=False):\n",
    "        self.n_classes = inputs.size(1)\n",
    "\n",
    "        if softmax:\n",
    "            inputs = torch.softmax(inputs, dim=1)\n",
    "        target = self._one_hot_encoder(target)\n",
    "        if weight is None:\n",
    "            weight = [1] * self.n_classes\n",
    "        assert inputs.size() == target.size(), 'predict {} & target {} shape do not match'.format(inputs.size(), target.size())\n",
    "        class_wise_dice = []\n",
    "        loss = 0.0\n",
    "        for i in range(0, self.n_classes):\n",
    "            dice = self._dice_loss(inputs[:, i], target[:, i])\n",
    "            class_wise_dice.append(1.0 - dice.item())\n",
    "            loss += dice * weight[i]\n",
    "        return loss / self.n_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.222967Z",
     "start_time": "2024-05-25T06:45:12.215329Z"
    }
   },
   "id": "ef9cb8147e4a7cbb"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class CrossEntropyDiceLoss(nn.CrossEntropyLoss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    def forward(self, pred, label):\n",
    "        label = label.long()\n",
    "        loss = super().forward(pred, label)\n",
    "        loss += self.dice_loss(pred, label, softmax=True)\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.223044Z",
     "start_time": "2024-05-25T06:45:12.218554Z"
    }
   },
   "id": "ae4529c09b175888"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.7135)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "pred = torch.rand(size=(8, 2, 224, 224), dtype=torch.float)\n",
    "label = torch.ones(size=(8, 224, 224), dtype=torch.long)\n",
    "loss_fn(pred, label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.280865Z",
     "start_time": "2024-05-25T06:45:12.221787Z"
    }
   },
   "id": "49b1c6408f8eeb2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义优化器"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c1a3d06739cddb5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9, weight_decay=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T06:45:12.281491Z",
     "start_time": "2024-05-25T06:45:12.238358Z"
    }
   },
   "id": "5c5226666a4a014d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练的逻辑"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bb353ecac4058d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, iter_num 1, loss 0.7228633761405945\n",
      "epoch 1, iter_num 2, loss 0.6646068096160889\n",
      "epoch 1, iter_num 3, loss 0.5917874574661255\n",
      "epoch 1, iter_num 4, loss 0.5465378165245056\n",
      "epoch 1, iter_num 5, loss 0.5051383376121521\n",
      "epoch 1, iter_num 6, loss 0.5223806500434875\n",
      "epoch 1, iter_num 7, loss 0.44889774918556213\n",
      "epoch 1, iter_num 8, loss 0.4270009994506836\n",
      "epoch 1, iter_num 9, loss 0.4629998803138733\n",
      "epoch 1, iter_num 10, loss 0.38265082240104675\n",
      "epoch 1, iter_num 11, loss 0.3557879626750946\n",
      "epoch 1, iter_num 12, loss 0.36341339349746704\n",
      "epoch 1, iter_num 13, loss 0.3122871518135071\n",
      "epoch 1, iter_num 14, loss 0.30525827407836914\n",
      "epoch 1, iter_num 15, loss 0.28260213136672974\n",
      "epoch 1, iter_num 16, loss 0.30867108702659607\n"
     ]
    }
   ],
   "source": [
    "epochs = 2  # 在数据集上训练 2 轮\n",
    "iter_num = 1\n",
    "device = torch.device('cuda')  # gpu 设备\n",
    "\n",
    "net.train()  # 设置为训练模型\n",
    "# net.to(device)  # 把网络移动到 显存 上\n",
    "\n",
    "# 如果不把 网络 和 数据移动到显存中，那么在训练的时候就是使用 cpu 训练\n",
    "for epoch in range(1, epochs+1):\n",
    "    for inputs, labels in dataloader:\n",
    "        # 把数据移动到显存中\n",
    "        # inputs, label = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels.long())\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "\n",
    "        # 更新梯度\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'epoch {epoch}, iter_num {iter_num}, loss {loss}')\n",
    "        iter_num += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-25T06:45:12.242016Z"
    }
   },
   "id": "467b5e26ea486837"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
